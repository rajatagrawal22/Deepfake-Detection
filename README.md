In the recent years deepfake technology has 
been advancing rapidly. This has increased the risk factor for 
the privacy of individuals , their reputations and has even
caused threat to the national security of many nations by 
spreading false information. Stopping the spread of fake news 
or information created by deepfake technology has become a 
rising issue for the society. Deep learning models are a great 
help in detecting such fake or synthesized information but
these models are prone to adversarial noise attacks which
might cause the model to misclassify the fake data. To 
overcome these problems a novel approach has been proposed 
here where a deep learning model with the combination of pretrained VGG16 and a custom-made CNN has been used to 
detect such deepfakes in CELEB-DF dataset. To evaluate the
performance of the model against the adversarial noise attacks, 
two types of noise attacks are simulated which are ‘gaussian’
noise attack and ‘Salt and Paper’ noise attack. Models 
performance is being evaluated based on different evaluation 
matrices such as Accuracy, Precision, Recall and AUC etc. The 
results of this projects show that the model performance 
decreased significantly for ‘ salt and paper’ noise attack but 
was able to tackle ‘gaussian’ attack effectively. Overall, this 
project shows the importance of developing the robust 
deepfake classification models and the effects of adversarial
attacks on them . The results of this project can be used to 
improve and create more advanced deepfake detection models
in future
